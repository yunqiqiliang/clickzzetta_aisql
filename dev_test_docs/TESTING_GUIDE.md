# ClickZetta AI SQL Functions æµ‹è¯•æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [æµ‹è¯•æ¦‚è¿°](#æµ‹è¯•æ¦‚è¿°)
2. [æµ‹è¯•ç¯å¢ƒå‡†å¤‡](#æµ‹è¯•ç¯å¢ƒå‡†å¤‡)
3. [æµ‹è¯•å·¥å…·ä»‹ç»](#æµ‹è¯•å·¥å…·ä»‹ç»)
4. [è¿è¡Œæµ‹è¯•](#è¿è¡Œæµ‹è¯•)
5. [æµ‹è¯•ç­–ç•¥](#æµ‹è¯•ç­–ç•¥)
6. [æµ‹è¯•ç”¨ä¾‹è®¾è®¡](#æµ‹è¯•ç”¨ä¾‹è®¾è®¡)
7. [æ€§èƒ½æµ‹è¯•](#æ€§èƒ½æµ‹è¯•)
8. [æµ‹è¯•æŠ¥å‘Šè§£è¯»](#æµ‹è¯•æŠ¥å‘Šè§£è¯»)
9. [æŒç»­é›†æˆ](#æŒç»­é›†æˆ)
10. [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)

## æµ‹è¯•æ¦‚è¿°

ClickZetta AI Functions æµ‹è¯•ä½“ç³»åŒ…å«ï¼š
- **åŠŸèƒ½æµ‹è¯•**ï¼šéªŒè¯30ä¸ªAIå‡½æ•°çš„æ­£ç¡®æ€§
- **æ€§èƒ½æµ‹è¯•**ï¼šç¡®ä¿å“åº”æ—¶é—´å’Œæ•°æ®å¤§å°ç¬¦åˆè¦æ±‚
- **å›å½’æµ‹è¯•**ï¼šé˜²æ­¢æ–°ä¿®æ”¹ç ´åç°æœ‰åŠŸèƒ½
- **é›†æˆæµ‹è¯•**ï¼šéªŒè¯ä¸ClickZettaå¹³å°çš„å…¼å®¹æ€§

### æµ‹è¯•æŒ‡æ ‡
- **åŠŸèƒ½è¦†ç›–ç‡**ï¼š100%ï¼ˆæ‰€æœ‰30ä¸ªå‡½æ•°ï¼‰
- **æˆåŠŸç‡ç›®æ ‡**ï¼šâ‰¥90%
- **æ€§èƒ½ç›®æ ‡**ï¼šå¹³å‡å“åº”æ—¶é—´ <5ç§’
- **æ•°æ®ä¼˜åŒ–**ï¼šç¬¦åˆJIRA-001è¦æ±‚ï¼ˆ67%å‹ç¼©ç‡ï¼‰

## æµ‹è¯•ç¯å¢ƒå‡†å¤‡

### 1. å®‰è£…æµ‹è¯•ä¾èµ–

```bash
# åŸºç¡€æµ‹è¯•ç¯å¢ƒ
pip install pytest pytest-asyncio pytest-timeout

# æ€§èƒ½æµ‹è¯•å·¥å…·
pip install memory_profiler line_profiler

# æµ‹è¯•æŠ¥å‘Š
pip install pytest-html pytest-json-report
```

### 2. é…ç½®æµ‹è¯•ç¯å¢ƒ

```bash
# è®¾ç½®APIå¯†é’¥ï¼ˆå¿…éœ€ï¼‰
export TEST_DASHSCOPE_API_KEY="sk-xxxxxxx"

# å¯é€‰ï¼šè®¾ç½®æµ‹è¯•æ¨¡å¼
export TEST_MODE="quick"  # quick/full/performance

# å¯é€‰ï¼šè®¾ç½®æµ‹è¯•è¾“å‡ºç›®å½•
export TEST_OUTPUT_DIR="./test_results"
```

### 3. å‡†å¤‡æµ‹è¯•æ•°æ®

```bash
# ç”Ÿæˆæµ‹è¯•æ•°æ®
python tests/prepare_test_data.py

# éªŒè¯æµ‹è¯•æ•°æ®
ls -la data/
# åº”è¯¥çœ‹åˆ°ï¼š
# - test_config.json
# - batch_test_data.json
# - test_images.json
# - test_documents.json
```

## æµ‹è¯•å·¥å…·ä»‹ç»

### 1. test_complete_coverage.py
å®Œæ•´çš„åŠŸèƒ½æµ‹è¯•å¥—ä»¶ï¼Œæµ‹è¯•æ‰€æœ‰30ä¸ªå‡½æ•°ã€‚

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•
python tests/test_complete_coverage.py $TEST_DASHSCOPE_API_KEY

# æµ‹è¯•ç‰¹å®šç±»åˆ«
python tests/test_complete_coverage.py $TEST_DASHSCOPE_API_KEY --category æ–‡æœ¬å¤„ç†

# æµ‹è¯•å•ä¸ªå‡½æ•°
python tests/test_complete_coverage.py $TEST_DASHSCOPE_API_KEY --function ai_text_summarize
```

### 2. quick_validation.py
å¿«é€ŸéªŒè¯æ ¸å¿ƒåŠŸèƒ½ï¼ˆ10ä¸ªæœ€å¸¸ç”¨å‡½æ•°ï¼‰ã€‚

```bash
# å¿«é€ŸéªŒè¯ï¼ˆ2-3åˆ†é’Ÿï¼‰
python tests/quick_validation.py $TEST_DASHSCOPE_API_KEY

# è¾“å‡ºç®€åŒ–æŠ¥å‘Š
python tests/quick_validation.py $TEST_DASHSCOPE_API_KEY --simple
```

### 3. smart_analyzer.py
æ™ºèƒ½åˆ†ææµ‹è¯•ç»“æœï¼Œè¯†åˆ«é—®é¢˜æ¨¡å¼ã€‚

```bash
# åˆ†ææœ€æ–°æµ‹è¯•ç»“æœ
python tests/smart_analyzer.py

# åˆ†æç‰¹å®šæµ‹è¯•æŠ¥å‘Š
python tests/smart_analyzer.py --report test_report_20250614.json

# ç”Ÿæˆä¼˜åŒ–å»ºè®®
python tests/smart_analyzer.py --suggest-optimizations
```

### 4. æ‰¹é‡æµ‹è¯•å·¥å…·

```bash
# æ‰¹é‡æµ‹è¯•æ‰€æœ‰å‡½æ•°
python tests/run_batch_tests.py $TEST_DASHSCOPE_API_KEY

# å¹¶è¡Œæµ‹è¯•ï¼ˆåŠ é€Ÿï¼‰
python tests/run_batch_tests.py $TEST_DASHSCOPE_API_KEY --parallel 4

# ç”Ÿæˆæµ‹è¯•çŸ©é˜µ
python tests/run_batch_tests.py $TEST_DASHSCOPE_API_KEY --matrix
```

## è¿è¡Œæµ‹è¯•

### åŸºç¡€æµ‹è¯•æµç¨‹

```bash
# 1. å¿«é€ŸéªŒè¯ç¯å¢ƒ
python tests/check_test_env.py

# 2. è¿è¡Œæ ¸å¿ƒæµ‹è¯•
python tests/quick_validation.py $TEST_DASHSCOPE_API_KEY

# 3. è¿è¡Œå®Œæ•´æµ‹è¯•
python tests/test_complete_coverage.py $TEST_DASHSCOPE_API_KEY

# 4. åˆ†æç»“æœ
python tests/smart_analyzer.py
```

### é«˜çº§æµ‹è¯•é€‰é¡¹

```bash
# è¯¦ç»†æ—¥å¿—æ¨¡å¼
python tests/test_complete_coverage.py $TEST_DASHSCOPE_API_KEY --verbose

# ä¿å­˜åŸå§‹å“åº”
python tests/test_complete_coverage.py $TEST_DASHSCOPE_API_KEY --save-responses

# é‡è¯•å¤±è´¥çš„æµ‹è¯•
python tests/test_complete_coverage.py $TEST_DASHSCOPE_API_KEY --retry-failed

# è·³è¿‡æ…¢é€Ÿæµ‹è¯•
python tests/test_complete_coverage.py $TEST_DASHSCOPE_API_KEY --skip-slow
```

### æŒç»­æµ‹è¯•

```bash
# ç›‘è§†æ¨¡å¼ï¼ˆæ–‡ä»¶å˜åŒ–æ—¶è‡ªåŠ¨æµ‹è¯•ï¼‰
python tests/watch_and_test.py

# å®šæ—¶æµ‹è¯•ï¼ˆæ¯å°æ—¶ï¼‰
python tests/scheduled_test.py --interval 3600
```

## æµ‹è¯•ç­–ç•¥

### 1. åˆ†å±‚æµ‹è¯•ç­–ç•¥

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    E2Eé›†æˆæµ‹è¯•ï¼ˆ10%ï¼‰    â”‚  <- å®Œæ•´çš„ClickZettaéƒ¨ç½²æµ‹è¯•
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    åŠŸèƒ½æµ‹è¯•ï¼ˆ60%ï¼‰       â”‚  <- æ¯ä¸ªå‡½æ•°çš„åŠŸèƒ½éªŒè¯
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    å•å…ƒæµ‹è¯•ï¼ˆ30%ï¼‰       â”‚  <- è¾…åŠ©å‡½æ•°å’Œå·¥å…·ç±»
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. æµ‹è¯•ä¼˜å…ˆçº§

**P0 - å…³é”®è·¯å¾„**ï¼ˆå¿…é¡»é€šè¿‡ï¼‰
- æ–‡æœ¬æ‘˜è¦ã€æƒ…æ„Ÿåˆ†æã€å®ä½“æå–
- æ–‡æœ¬å‘é‡åŒ–ã€è¯­ä¹‰ç›¸ä¼¼åº¦
- å›¾ç‰‡æè¿°ã€OCR

**P1 - é‡è¦åŠŸèƒ½**ï¼ˆåº”è¯¥é€šè¿‡ï¼‰
- ç¿»è¯‘ã€å…³é”®è¯æå–
- èšç±»å‡†å¤‡ã€å‘é‡æœç´¢
- è§†é¢‘åˆ†æã€è¯­éŸ³è½¬æ–‡å­—

**P2 - è¾…åŠ©åŠŸèƒ½**ï¼ˆå¯ä»¥å¤±è´¥ï¼‰
- é«˜çº§ä¸šåŠ¡åœºæ™¯å‡½æ•°
- éœ€è¦ç‰¹æ®Šé…é¢çš„å‡½æ•°

### 3. æµ‹è¯•æ•°æ®ç­–ç•¥

```python
# æµ‹è¯•æ•°æ®åˆ†ç±»
test_data_types = {
    "edge_cases": [
        "",  # ç©ºå­—ç¬¦ä¸²
        " ",  # çº¯ç©ºæ ¼
        "a" * 10000,  # è¶…é•¿æ–‡æœ¬
        "ğŸ‰ğŸ˜€",  # è¡¨æƒ…ç¬¦å·
        "<script>alert()</script>",  # ç‰¹æ®Šå­—ç¬¦
    ],
    "normal_cases": [
        "æ­£å¸¸çš„ä¸­æ–‡æ–‡æœ¬",
        "Normal English text",
        "æ··åˆæ–‡æœ¬ with English",
    ],
    "business_cases": [
        # çœŸå®ä¸šåŠ¡åœºæ™¯æ•°æ®
    ]
}
```

## æµ‹è¯•ç”¨ä¾‹è®¾è®¡

### 1. åŠŸèƒ½æµ‹è¯•ç”¨ä¾‹æ¨¡æ¿

```python
def test_ai_function_template():
    """æµ‹è¯•ç”¨ä¾‹æ¨¡æ¿"""
    # Arrange - å‡†å¤‡æµ‹è¯•æ•°æ®
    test_input = {
        "text": "æµ‹è¯•æ–‡æœ¬",
        "api_key": TEST_API_KEY,
        "model_name": "qwen-plus"
    }
    
    # Act - æ‰§è¡Œæµ‹è¯•
    result = ai_function_impl([[
        test_input["text"],
        test_input["api_key"],
        test_input["model_name"]
    ]])
    
    # Assert - éªŒè¯ç»“æœ
    assert len(result) == 1
    response = json.loads(result[0])
    
    # éªŒè¯å¿…éœ€å­—æ®µ
    assert "result" in response or "error" in response
    if "result" in response:
        assert len(response["result"]) > 0
    
    # éªŒè¯å“åº”æ ¼å¼
    assert isinstance(response, dict)
```

### 2. è¾¹ç•Œæµ‹è¯•

```python
# ç©ºè¾“å…¥æµ‹è¯•
def test_empty_input():
    result = ai_text_summarize_impl([["", api_key]])
    response = json.loads(result[0])
    assert "error" in response
    assert "ç©º" in response["error"] or "empty" in response["error"].lower()

# è¶…é•¿è¾“å…¥æµ‹è¯•
def test_large_input():
    large_text = "æµ‹è¯•" * 5000  # 10000å­—ç¬¦
    result = ai_text_summarize_impl([[large_text, api_key]])
    response = json.loads(result[0])
    # åº”è¯¥æˆåŠŸå¤„ç†æˆ–è¿”å›åˆç†çš„é”™è¯¯
    assert "result" in response or "error" in response

# ç‰¹æ®Šå­—ç¬¦æµ‹è¯•
def test_special_characters():
    special_text = "æµ‹è¯•\n\t\rç‰¹æ®Š\"å­—ç¬¦'<>&"
    result = ai_text_summarize_impl([[special_text, api_key]])
    response = json.loads(result[0])
    assert len(result[0]) > 0  # ç¡®ä¿ä¸ä¼šå´©æºƒ
```

### 3. æ€§èƒ½æµ‹è¯•ç”¨ä¾‹

```python
import time

def test_performance():
    """æ€§èƒ½æµ‹è¯•"""
    start_time = time.time()
    
    # æ‰§è¡Œå‡½æ•°
    result = ai_text_summarize_impl([[test_text, api_key]])
    
    end_time = time.time()
    execution_time = end_time - start_time
    
    # éªŒè¯æ€§èƒ½æŒ‡æ ‡
    assert execution_time < 5.0, f"æ‰§è¡Œæ—¶é—´ {execution_time}s è¶…è¿‡é™åˆ¶"
    
    # éªŒè¯å“åº”å¤§å°
    response_size = len(result[0])
    assert response_size < 10000, f"å“åº”å¤§å° {response_size} è¶…è¿‡é™åˆ¶"
```

## æ€§èƒ½æµ‹è¯•

### 1. å“åº”æ—¶é—´æµ‹è¯•

```bash
# è¿è¡Œæ€§èƒ½æµ‹è¯•å¥—ä»¶
python tests/performance_test.py $TEST_DASHSCOPE_API_KEY

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
python tests/performance_test.py $TEST_DASHSCOPE_API_KEY --report

# å‹åŠ›æµ‹è¯•ï¼ˆå¹¶å‘ï¼‰
python tests/performance_test.py $TEST_DASHSCOPE_API_KEY --concurrent 10
```

### 2. å†…å­˜ä½¿ç”¨æµ‹è¯•

```bash
# å†…å­˜åˆ†æ
python -m memory_profiler tests/memory_test.py

# ç”Ÿæˆå†…å­˜ä½¿ç”¨å›¾è¡¨
python tests/memory_test.py --plot
```

### 3. æ•°æ®å¤§å°ä¼˜åŒ–æµ‹è¯•ï¼ˆJIRA-001 éªŒè¯ï¼‰

#### å“åº”å¤§å°æµ‹è¯•æ¡†æ¶
```python
# test_response_optimization.py
import json
import sys
from collections import defaultdict

class ResponseOptimizationTester:
    """å“åº”ä¼˜åŒ–æ•ˆæœæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.results = defaultdict(list)
        self.target_compression = 0.67  # JIRA-001 ç›®æ ‡
        
    def test_function_optimization(self, func_name, test_input, api_key):
        """æµ‹è¯•å•ä¸ªå‡½æ•°çš„ä¼˜åŒ–æ•ˆæœ"""
        # è·å–å‡½æ•°å“åº”
        response = call_function(func_name, test_input, api_key)
        response_json = json.loads(response)
        
        # åˆ†æå“åº”
        analysis = self.analyze_response(response_json)
        
        # æ£€æµ‹å†—ä½™å†…å®¹
        redundancy = self.detect_redundancy(response_json)
        
        # è®¡ç®—ä¼˜åŒ–æ½œåŠ›
        optimization_potential = self.calculate_optimization_potential(
            response, redundancy
        )
        
        self.results[func_name].append({
            "original_size": len(response),
            "redundancy_score": redundancy["score"],
            "optimization_potential": optimization_potential,
            "issues": redundancy["issues"]
        })
        
        return analysis
    
    def detect_redundancy(self, response_obj):
        """æ£€æµ‹å“åº”ä¸­çš„å†—ä½™å†…å®¹"""
        issues = []
        redundancy_bytes = 0
        
        # æ£€æŸ¥ç¤¼è²Œç”¨è¯­
        politeness_patterns = [
            "æ„Ÿè°¢æ‚¨", "å¸Œæœ›å¯¹æ‚¨æœ‰å¸®åŠ©", "è¯·é—®è¿˜æœ‰ä»€ä¹ˆ",
            "æ ¹æ®æ‚¨çš„è¦æ±‚", "æˆ‘å·²ç»ä¸ºæ‚¨", "ä»¥ä¸‹æ˜¯"
        ]
        
        response_str = json.dumps(response_obj, ensure_ascii=False)
        for pattern in politeness_patterns:
            if pattern in response_str:
                issues.append(f"åŒ…å«å†—ä½™ç¤¼è²Œç”¨è¯­: {pattern}")
                redundancy_bytes += len(pattern) * response_str.count(pattern)
        
        # æ£€æŸ¥è¿‡åº¦åµŒå¥—
        nesting_depth = self.get_nesting_depth(response_obj)
        if nesting_depth > 3:
            issues.append(f"è¿‡åº¦åµŒå¥—: æ·±åº¦{nesting_depth}")
            redundancy_bytes += 50 * (nesting_depth - 3)
        
        # æ£€æŸ¥ç©ºå€¼å’Œnull
        empty_count = self.count_empty_values(response_obj)
        if empty_count > 0:
            issues.append(f"åŒ…å«{empty_count}ä¸ªç©ºå€¼")
            redundancy_bytes += empty_count * 10
        
        # æ£€æŸ¥é‡å¤çš„å­—æ®µå
        if self.has_redundant_keys(response_obj):
            issues.append("å­˜åœ¨å†—ä½™çš„å­—æ®µç»“æ„")
            redundancy_bytes += 100
        
        return {
            "score": redundancy_bytes / len(response_str),
            "bytes": redundancy_bytes,
            "issues": issues
        }
    
    def get_nesting_depth(self, obj, depth=0):
        """è®¡ç®—JSONåµŒå¥—æ·±åº¦"""
        if isinstance(obj, dict):
            return max([self.get_nesting_depth(v, depth + 1) 
                       for v in obj.values()], default=depth)
        elif isinstance(obj, list) and obj:
            return max([self.get_nesting_depth(item, depth + 1) 
                       for item in obj])
        return depth
    
    def count_empty_values(self, obj):
        """ç»Ÿè®¡ç©ºå€¼æ•°é‡"""
        count = 0
        if isinstance(obj, dict):
            for v in obj.values():
                if v is None or v == "" or v == []:
                    count += 1
                else:
                    count += self.count_empty_values(v)
        elif isinstance(obj, list):
            for item in obj:
                count += self.count_empty_values(item)
        return count
    
    def generate_report(self):
        """ç”Ÿæˆä¼˜åŒ–æµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“Š å“åº”ä¼˜åŒ–æµ‹è¯•æŠ¥å‘Š")
        print("=" * 60)
        
        total_functions = len(self.results)
        optimized_functions = 0
        
        for func_name, tests in self.results.items():
            avg_size = sum(t["original_size"] for t in tests) / len(tests)
            avg_redundancy = sum(t["redundancy_score"] for t in tests) / len(tests)
            
            print(f"\n{func_name}:")
            print(f"  å¹³å‡å¤§å°: {avg_size:.0f} bytes")
            print(f"  å†—ä½™åº¦: {avg_redundancy:.1%}")
            
            # æ˜¾ç¤ºä¸»è¦é—®é¢˜
            all_issues = []
            for t in tests:
                all_issues.extend(t["issues"])
            
            issue_counts = defaultdict(int)
            for issue in all_issues:
                issue_counts[issue] += 1
            
            print("  ä¸»è¦é—®é¢˜:")
            for issue, count in sorted(issue_counts.items(), 
                                      key=lambda x: x[1], 
                                      reverse=True)[:3]:
                print(f"    - {issue} (å‡ºç°{count}æ¬¡)")
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦ä¼˜åŒ–
            if avg_redundancy > 0.3:
                print("  âš ï¸  å»ºè®®ä¼˜åŒ–")
                optimized_functions += 1
            else:
                print("  âœ… å·²ä¼˜åŒ–")
        
        print(f"\næ€»ç»“: {optimized_functions}/{total_functions} ä¸ªå‡½æ•°éœ€è¦ä¼˜åŒ–")
```

#### æ‰¹é‡ä¼˜åŒ–æµ‹è¯•è„šæœ¬
```python
# batch_optimization_test.py
def test_all_functions_optimization():
    """æ‰¹é‡æµ‹è¯•æ‰€æœ‰å‡½æ•°çš„ä¼˜åŒ–æƒ…å†µ"""
    tester = ResponseOptimizationTester()
    
    # æµ‹è¯•é…ç½®
    test_cases = {
        "ai_text_summarize": {
            "input": "è¿™æ˜¯ä¸€æ®µå¾ˆé•¿çš„æµ‹è¯•æ–‡æœ¬...",
            "expected_max_size": 3000
        },
        "ai_text_sentiment_analyze": {
            "input": "è¿™ä¸ªäº§å“éå¸¸å¥½ç”¨",
            "expected_max_size": 500
        },
        # ... å…¶ä»–å‡½æ•°
    }
    
    for func_name, config in test_cases.items():
        print(f"æµ‹è¯• {func_name}...")
        
        # æµ‹è¯•åŸå§‹ç‰ˆæœ¬
        result = tester.test_function_optimization(
            func_name, 
            config["input"], 
            api_key
        )
        
        # éªŒè¯å¤§å°é™åˆ¶
        if result["size"] > config["expected_max_size"]:
            print(f"  âŒ è¶…å‡ºé¢„æœŸå¤§å°: {result['size']} > {config['expected_max_size']}")
        else:
            print(f"  âœ… å¤§å°ç¬¦åˆé¢„æœŸ: {result['size']} bytes")
    
    # ç”ŸæˆæŠ¥å‘Š
    tester.generate_report()
```

#### ä¼˜åŒ–å‰åå¯¹æ¯”æµ‹è¯•
```python
def compare_before_after_optimization():
    """å¯¹æ¯”ä¼˜åŒ–å‰åçš„æ•ˆæœ"""
    
    # æ¨¡æ‹Ÿä¼˜åŒ–å‰çš„å“åº”
    before = {
        "status": "success",
        "message": "å¤„ç†æˆåŠŸ",
        "data": {
            "result": {
                "content": "æ ¹æ®æ‚¨çš„è¦æ±‚ï¼Œæˆ‘å·²ç»ä¸ºæ‚¨åˆ†æäº†è¿™æ®µæ–‡æœ¬ã€‚è¿™æ®µæ–‡æœ¬è¡¨è¾¾äº†æ­£é¢æƒ…æ„Ÿã€‚å¸Œæœ›è¿™ä¸ªç»“æœå¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ã€‚",
                "sentiment": "æ­£é¢",
                "score": 0.95,
                "confidence": "high",
                "details": {
                    "positive": 0.95,
                    "negative": 0.03,
                    "neutral": 0.02
                }
            },
            "metadata": {
                "model": "qwen-plus",
                "version": "1.0",
                "timestamp": "2024-01-01T00:00:00Z"
            }
        }
    }
    
    # ä¼˜åŒ–åçš„å“åº”
    after = {
        "sentiment": "æ­£é¢",
        "score": 0.95
    }
    
    # è®¡ç®—å‹ç¼©ç‡
    before_size = len(json.dumps(before, ensure_ascii=False))
    after_size = len(json.dumps(after, ensure_ascii=False))
    compression = 1 - (after_size / before_size)
    
    print(f"ä¼˜åŒ–å‰: {before_size} bytes")
    print(f"ä¼˜åŒ–å: {after_size} bytes")
    print(f"å‹ç¼©ç‡: {compression:.1%}")
    print(f"è¾¾åˆ°JIRA-001ç›®æ ‡: {'âœ…' if compression >= 0.67 else 'âŒ'}")
```

#### å‘é‡å‡½æ•°ç‰¹æ®Šæµ‹è¯•
```python
def test_vector_functions_should_not_compress():
    """éªŒè¯å‘é‡å‡½æ•°ä¸åº”è¯¥è¢«å‹ç¼©"""
    vector_functions = [
        "ai_text_to_embedding",
        "ai_text_clustering_prepare",
        "ai_image_to_embedding"
    ]
    
    for func_name in vector_functions:
        response = call_function(func_name, test_input, api_key)
        data = json.loads(response)
        
        # æ£€æŸ¥å‘é‡ç»´åº¦
        if "embedding" in data:
            vector_size = len(data["embedding"])
            vector_bytes = len(json.dumps(data["embedding"]))
            
            print(f"{func_name}:")
            print(f"  å‘é‡ç»´åº¦: {vector_size}")
            print(f"  æ•°æ®å¤§å°: {vector_bytes} bytes")
            print(f"  åˆ¤å®š: {'âœ… æ­£å¸¸' if vector_bytes > 10000 else 'âŒ å¯èƒ½è¢«é”™è¯¯å‹ç¼©'}")
```

## æµ‹è¯•æŠ¥å‘Šè§£è¯»

### 1. æµ‹è¯•æŠ¥å‘Šç»“æ„

```json
{
    "summary": {
        "total_functions": 30,
        "successful": 28,
        "failed": 2,
        "success_rate": 0.933,
        "average_response_time": 3.44,
        "test_duration": 245.6
    },
    "details": {
        "ai_text_summarize": {
            "status": "success",
            "response_time": 2.3,
            "response_size": 1248,
            "output_sample": "..."
        }
    },
    "failures": [
        {
            "function": "ai_image_to_embedding",
            "error": "éœ€è¦æ›´é«˜APIé…é¢",
            "suggestion": "å‡çº§APIå¥—é¤"
        }
    ]
}
```

### 2. å…³é”®æŒ‡æ ‡è§£è¯»

- **æˆåŠŸç‡**ï¼š>90% ä¼˜ç§€ï¼Œ80-90% è‰¯å¥½ï¼Œ<80% éœ€æ”¹è¿›
- **å“åº”æ—¶é—´**ï¼š<3s ä¼˜ç§€ï¼Œ3-5s è‰¯å¥½ï¼Œ>5s éœ€ä¼˜åŒ–
- **æ•°æ®å¤§å°**ï¼šæ ¹æ®å‡½æ•°ç±»å‹åˆ¤æ–­
  - æ–‡æœ¬å‡½æ•°ï¼š<5KB
  - å‘é‡å‡½æ•°ï¼š20-30KBï¼ˆæ­£å¸¸ï¼‰
  - å¤šæ¨¡æ€å‡½æ•°ï¼š<10KB

### 3. é—®é¢˜åˆ†ç±»

```python
# smart_analyzer.py çš„é—®é¢˜åˆ†ç±»
problem_categories = {
    "api_errors": ["AuthenticationError", "RateLimitError"],
    "input_errors": ["ç©ºè¾“å…¥", "æ ¼å¼é”™è¯¯"],
    "timeout_errors": ["è¶…æ—¶", "å“åº”æ…¢"],
    "size_errors": ["å“åº”è¿‡å¤§", "å†…å­˜æº¢å‡º"]
}
```

## åˆ†é˜¶æ®µéƒ¨ç½²æµ‹è¯•ç­–ç•¥

### ğŸ¯ ç»è¿‡éªŒè¯çš„æœ€ä½³å®è·µ

åŸºäºå®é™…é¡¹ç›®ç»éªŒï¼Œåˆ†é˜¶æ®µéƒ¨ç½²æµ‹è¯•æ˜¯å®šä½"å‡½æ•°æ‰¾ä¸åˆ°"ç­‰éƒ¨ç½²é—®é¢˜çš„æœ€æœ‰æ•ˆæ–¹æ³•ã€‚

### æµ‹è¯•é˜¶æ®µè®¾è®¡

```bash
# åˆ›å»ºæµ‹è¯•ç›®å½•
mkdir deployment_tests
cd deployment_tests
```

#### ç¬¬1é˜¶æ®µï¼šåŸºç¡€ç¯å¢ƒæµ‹è¯•
```python
# test_stage1_basic.py
from clickzetta.external_function.annotate import annotate

@annotate("stage1_echo", 
    [{"name": "message", "type": "string"}],
    {"type": "string"})
def stage1_echo_impl(rows):
    """æœ€åŸºç¡€çš„æµ‹è¯•ï¼Œæ— ä»»ä½•ä¾èµ–"""
    return [f"Echo: {row[0]}" for row in rows]

# SQLæµ‹è¯•
# SELECT stage1_echo('Hello ClickZetta');
# é¢„æœŸè¾“å‡º: "Echo: Hello ClickZetta"
```

#### ç¬¬2é˜¶æ®µï¼šPythonæ ‡å‡†åº“æµ‹è¯•
```python
# test_stage2_stdlib.py
import json
import datetime
from clickzetta.external_function.annotate import annotate

@annotate("stage2_stdlib", 
    [{"name": "data", "type": "string"}],
    {"type": "string"})
def stage2_stdlib_impl(rows):
    """æµ‹è¯•Pythonæ ‡å‡†åº“åŠŸèƒ½"""
    results = []
    for row in rows:
        result = {
            "input": row[0],
            "timestamp": datetime.datetime.now().isoformat(),
            "json_works": True
        }
        results.append(json.dumps(result))
    return results
```

#### ç¬¬3é˜¶æ®µï¼šç¬¬ä¸‰æ–¹ä¾èµ–æµ‹è¯•
```python
# test_stage3_dependencies.py
import json
import dashscope
import requests
from clickzetta.external_function.annotate import annotate

@annotate("stage3_check_deps", 
    [{"name": "check_type", "type": "string"}],
    {"type": "string"})
def stage3_check_deps_impl(rows):
    """éªŒè¯ç¬¬ä¸‰æ–¹åŒ…æ˜¯å¦æ­£ç¡®åŠ è½½"""
    results = []
    for row in rows:
        deps_info = {
            "dashscope_version": getattr(dashscope, '__version__', 'unknown'),
            "requests_version": requests.__version__,
            "dashscope_module": str(type(dashscope)),
            "check_type": row[0]
        }
        results.append(json.dumps(deps_info))
    return results
```

#### ç¬¬4é˜¶æ®µï¼šç½‘ç»œè¿æ¥æµ‹è¯•
```python
# test_stage4_network.py
import json
import requests
from clickzetta.external_function.annotate import annotate

@annotate("stage4_network", 
    [{"name": "url", "type": "string"}],
    {"type": "string"})
def stage4_network_impl(rows):
    """æµ‹è¯•ç½‘ç»œè¿æ¥èƒ½åŠ›"""
    results = []
    for row in rows:
        try:
            response = requests.get(row[0], timeout=5)
            result = {
                "url": row[0],
                "status_code": response.status_code,
                "network": "connected"
            }
        except Exception as e:
            result = {
                "url": row[0],
                "error": str(e),
                "network": "failed"
            }
        results.append(json.dumps(result))
    return results
```

#### ç¬¬5é˜¶æ®µï¼šAPIå¯†é’¥æµ‹è¯•
```python
# test_stage5_api.py
import json
import dashscope
from clickzetta.external_function.annotate import annotate

@annotate("stage5_api_test", 
    [{"name": "api_key", "type": "string"}],
    {"type": "string"})
def stage5_api_test_impl(rows):
    """æµ‹è¯•APIå¯†é’¥æœ‰æ•ˆæ€§"""
    results = []
    for row in rows:
        try:
            # è®¾ç½®APIå¯†é’¥
            dashscope.api_key = row[0]
            
            # å°è¯•æœ€å°åŒ–çš„APIè°ƒç”¨
            from dashscope import Tokenization
            resp = Tokenization.call(
                model='qwen-turbo',
                messages=[{"role": "user", "content": "test"}]
            )
            
            result = {
                "api_status": "valid",
                "token_count": resp.usage.input_tokens
            }
        except Exception as e:
            result = {
                "api_status": "invalid",
                "error": str(e)[:100]  # æˆªæ–­é”™è¯¯ä¿¡æ¯
            }
        results.append(json.dumps(result))
    return results
```

### æ‰§è¡Œæµ‹è¯•æµç¨‹

```bash
# 1. æ‰“åŒ…æ¯ä¸ªé˜¶æ®µ
python package_stage_test.py stage1
python package_stage_test.py stage2
# ... ä¾æ¬¡ç±»æ¨

# 2. éƒ¨ç½²å¹¶æµ‹è¯•æ¯ä¸ªé˜¶æ®µ
# ä¸Šä¼  stage1.zip
PUT 'file://stage1.zip' TO 'volume://tests/stage1.zip';

# åˆ›å»ºå‡½æ•°
CREATE EXTERNAL FUNCTION stage1_echo(message STRING)
RETURNS STRING
AS 'volume://tests/stage1.zip'
CONNECTION = test_connection
RUNTIME = 'python3.8'
HANDLER = 'test_stage1_basic.stage1_echo_impl';

# æµ‹è¯•
SELECT stage1_echo('test');
```

### é—®é¢˜å®šä½æŒ‡å—

| å¤±è´¥é˜¶æ®µ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|---------|---------|---------|
| é˜¶æ®µ1 | Handlerè·¯å¾„é”™è¯¯ã€è£…é¥°å™¨é—®é¢˜ | æ£€æŸ¥æ¨¡å—å.å‡½æ•°åæ ¼å¼ |
| é˜¶æ®µ2 | Pythonç‰ˆæœ¬ä¸å…¼å®¹ | ç¡®è®¤ä½¿ç”¨python3.8 |
| é˜¶æ®µ3 | ä¾èµ–åŒ…æœªæ‰“åŒ… | æ£€æŸ¥ZIPåŒ…å†…å®¹ |
| é˜¶æ®µ4 | ç½‘ç»œé™åˆ¶ | æ£€æŸ¥VPCé…ç½®ã€å®‰å…¨ç»„ |
| é˜¶æ®µ5 | APIå¯†é’¥æ— æ•ˆ | éªŒè¯å¯†é’¥ã€æ£€æŸ¥é…é¢ |

### è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬

```python
# auto_stage_test.py
import subprocess
import time

stages = [
    ("stage1_echo", "SELECT stage1_echo('test')"),
    ("stage2_stdlib", "SELECT stage2_stdlib('test')"),
    ("stage3_check_deps", "SELECT stage3_check_deps('all')"),
    ("stage4_network", "SELECT stage4_network('https://httpbin.org/get')"),
    ("stage5_api_test", "SELECT stage5_api_test('sk-xxx')")
]

for func_name, test_sql in stages:
    print(f"\nğŸ§ª Testing {func_name}...")
    
    # æ‰§è¡ŒSQLæµ‹è¯•
    result = execute_sql(test_sql)
    
    if "error" in result.lower():
        print(f"âŒ {func_name} failed!")
        print(f"   Error: {result}")
        print("   Stopping at this stage for debugging.")
        break
    else:
        print(f"âœ… {func_name} passed!")
        time.sleep(2)  # é¿å…è¿‡å¿«æ‰§è¡Œ

print("\nğŸ“Š æµ‹è¯•å®Œæˆ!")
```

## æŒç»­é›†æˆ

### 1. GitHub Actions é…ç½®

```yaml
# .github/workflows/test.yml
name: AI Functions Test

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 */6 * * *'  # æ¯6å°æ—¶

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-html
    
    - name: Run tests
      env:
        TEST_DASHSCOPE_API_KEY: ${{ secrets.DASHSCOPE_API_KEY }}
      run: |
        python tests/test_complete_coverage.py $TEST_DASHSCOPE_API_KEY
    
    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v2
      with:
        name: test-results
        path: test_results/
```

### 2. æœ¬åœ°CIè„šæœ¬

```bash
#!/bin/bash
# scripts/run_ci_tests.sh

echo "ğŸš€ å¼€å§‹CIæµ‹è¯•æµç¨‹"

# 1. ä»£ç è´¨é‡æ£€æŸ¥
echo "ğŸ“ æ£€æŸ¥ä»£ç è´¨é‡..."
flake8 src/ tests/ || exit 1

# 2. è¿è¡Œæµ‹è¯•
echo "ğŸ§ª è¿è¡Œæµ‹è¯•å¥—ä»¶..."
python tests/test_complete_coverage.py $TEST_DASHSCOPE_API_KEY || exit 1

# 3. ç”ŸæˆæŠ¥å‘Š
echo "ğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š..."
python tests/smart_analyzer.py --ci-mode

# 4. æ£€æŸ¥è¦†ç›–ç‡
echo "ğŸ“ˆ æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡..."
python tests/check_coverage.py --threshold 90

echo "âœ… CIæµ‹è¯•å®Œæˆ!"
```

## æ•…éšœæ’æŸ¥

### 1. å¸¸è§é—®é¢˜è¯Šæ–­

```bash
# è¯Šæ–­è„šæœ¬
python tests/diagnose.py

# æ£€æŸ¥ç‰¹å®šé—®é¢˜
python tests/diagnose.py --check api-connection
python tests/diagnose.py --check response-format
python tests/diagnose.py --check performance
```

### 2. è°ƒè¯•æŠ€å·§

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# ä¿å­˜ä¸­é—´ç»“æœ
def debug_function(input_data):
    # ä¿å­˜è¾“å…¥
    with open("debug_input.json", "w") as f:
        json.dump(input_data, f, ensure_ascii=False)
    
    # æ‰§è¡Œå‡½æ•°
    result = ai_function(input_data)
    
    # ä¿å­˜è¾“å‡º
    with open("debug_output.json", "w") as f:
        json.dump(result, f, ensure_ascii=False)
    
    return result
```

### 3. é—®é¢˜ä¿®å¤æµç¨‹

1. **è¯†åˆ«é—®é¢˜**
   ```bash
   python tests/identify_failures.py
   ```

2. **éš”ç¦»æµ‹è¯•**
   ```bash
   python tests/test_single_function.py ai_function_name
   ```

3. **åº”ç”¨ä¿®å¤**
   ```bash
   python scripts/fix_function.py ai_function_name
   ```

4. **éªŒè¯ä¿®å¤**
   ```bash
   python tests/verify_fix.py ai_function_name
   ```

## æµ‹è¯•æœ€ä½³å®è·µ

### 1. æµ‹è¯•åŸåˆ™
- **ç‹¬ç«‹æ€§**ï¼šæ¯ä¸ªæµ‹è¯•åº”è¯¥ç‹¬ç«‹è¿è¡Œ
- **å¯é‡å¤**ï¼šæµ‹è¯•ç»“æœåº”è¯¥ä¸€è‡´
- **å¿«é€Ÿåé¦ˆ**ï¼šä¼˜å…ˆè¿è¡Œå¿«é€Ÿæµ‹è¯•
- **æœ‰æ„ä¹‰çš„æ–­è¨€**ï¼šéªŒè¯ä¸šåŠ¡é€»è¾‘ï¼Œä¸åªæ˜¯æŠ€æœ¯ç»†èŠ‚

### 2. æµ‹è¯•ç»„ç»‡
```
tests/
â”œâ”€â”€ unit/              # å•å…ƒæµ‹è¯•
â”œâ”€â”€ functional/        # åŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ performance/       # æ€§èƒ½æµ‹è¯•
â”œâ”€â”€ integration/       # é›†æˆæµ‹è¯•
â””â”€â”€ fixtures/          # æµ‹è¯•æ•°æ®
```

### 3. æµ‹è¯•å‘½å
```python
# å¥½çš„å‘½å
def test_text_summarize_returns_summary_with_key_points():
def test_empty_input_returns_error():
def test_large_text_processed_within_timeout():

# é¿å…çš„å‘½å
def test_1():
def test_function():
def test_it_works():
```

---

*æœ€åæ›´æ–°ï¼š2025-06-14*