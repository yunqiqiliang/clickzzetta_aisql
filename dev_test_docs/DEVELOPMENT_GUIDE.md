# ClickZetta AI SQL Functions å¼€å‘æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [å¼€å‘ç¯å¢ƒè®¾ç½®](#å¼€å‘ç¯å¢ƒè®¾ç½®)
3. [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
4. [å‡½æ•°å¼€å‘è§„èŒƒ](#å‡½æ•°å¼€å‘è§„èŒƒ)
5. [æ·»åŠ æ–°å‡½æ•°æŒ‡å—](#æ·»åŠ æ–°å‡½æ•°æŒ‡å—)
6. [è°ƒè¯•æŠ€å·§](#è°ƒè¯•æŠ€å·§)
7. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
8. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

## é¡¹ç›®æ¦‚è¿°

ClickZetta AI SQL Functions æ˜¯ä¸ºäº‘å™¨Lakehouseè®¾è®¡çš„AIå‡½æ•°é›†åˆï¼Œæä¾›30ä¸ªç”Ÿäº§çº§AIå‡½æ•°ï¼Œæ¶µç›–æ–‡æœ¬å¤„ç†ã€å‘é‡è®¡ç®—ã€å¤šæ¨¡æ€åˆ†æå’Œä¸šåŠ¡åœºæ™¯åº”ç”¨ã€‚

### æŠ€æœ¯æ ˆ
- **Python 3.8+** - ClickZetta External Functionè¿è¡Œæ—¶
- **DashScope API** - é˜¿é‡Œäº‘é€šä¹‰åƒé—®AIæœåŠ¡
- **è£…é¥°å™¨æ¨¡å¼** - `@annotate` ç”¨äºå‡½æ•°æ³¨å†Œ
- **JSONæ ¼å¼** - ç»Ÿä¸€çš„è¾“å…¥è¾“å‡ºæ ¼å¼

## å¼€å‘ç¯å¢ƒè®¾ç½®

### 1. å…‹éš†é¡¹ç›®
```bash
git clone https://github.com/your-org/clickzetta_aisql.git
cd clickzetta_aisql
```

### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
```bash
# ä½¿ç”¨ venv
python3 -m venv .venv
source .venv/bin/activate  # macOS/Linux
# æˆ–
.venv\Scripts\activate  # Windows

# ä½¿ç”¨ uvï¼ˆæ¨èï¼‰
uv venv
uv sync
```

### 3. å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### 4. è·å–å’Œé…ç½®APIå¯†é’¥

#### è·å–é€šä¹‰åƒé—® API Keyï¼ˆå¿…éœ€ï¼‰

1. **æ³¨å†Œé˜¿é‡Œäº‘è´¦å·**
   - è®¿é—® [é˜¿é‡Œäº‘å®˜ç½‘](https://www.aliyun.com)
   - å®Œæˆå®åè®¤è¯

2. **å¼€é€š DashScope æœåŠ¡**
   - è®¿é—® [DashScopeæ§åˆ¶å°](https://dashscope.console.aliyun.com)
   - é¦–æ¬¡è®¿é—®ä¼šæç¤ºå¼€é€šæœåŠ¡
   - åŒæ„æœåŠ¡åè®®å¹¶å¼€é€š

3. **åˆ›å»º API Key**
   - åœ¨ DashScope æ§åˆ¶å°ç‚¹å‡»"API-KEYç®¡ç†"
   - ç‚¹å‡»"åˆ›å»ºæ–°çš„API-KEY"
   - å¤åˆ¶ç”Ÿæˆçš„ API Keyï¼ˆæ ¼å¼ï¼š`sk-xxxxxxxxxxxxxxxx`ï¼‰
   - âš ï¸ **é‡è¦**ï¼šAPI Key åªæ˜¾ç¤ºä¸€æ¬¡ï¼Œè¯·ç«‹å³ä¿å­˜

4. **é…ç½® API Key**
   ```bash
   # æœ¬åœ°æµ‹è¯•
   export DASHSCOPE_API_KEY="sk-xxxxxxx"
   
   # æˆ–æ·»åŠ åˆ° .env æ–‡ä»¶
   echo "DASHSCOPE_API_KEY=sk-xxxxxxx" >> .env
   ```

5. **éªŒè¯ API Key**
   ```python
   # test_api_key.py
   import dashscope
   dashscope.api_key = "sk-xxxxxxx"
   
   from dashscope import Generation
   response = Generation.call(
       model='qwen-turbo',
       prompt='Hello',
       max_tokens=5
   )
   print("API Key æœ‰æ•ˆï¼" if response.status_code == 200 else "API Key æ— æ•ˆ")
   ```

#### API é…é¢è¯´æ˜
- **å…è´¹é¢åº¦**ï¼šæ–°ç”¨æˆ·æœ‰ä¸€å®šå…è´¹é¢åº¦
- **è®¡è´¹æ¨¡å¼**ï¼šæŒ‰ token ä½¿ç”¨é‡è®¡è´¹
- **æ¨¡å‹é€‰æ‹©**ï¼š
  - `qwen-turbo`ï¼šæœ€ä¾¿å®œï¼Œé€‚åˆæµ‹è¯•
  - `qwen-plus`ï¼šå¹³è¡¡æ€§èƒ½å’Œæˆæœ¬
  - `qwen-max`ï¼šæœ€å¼ºèƒ½åŠ›ï¼Œæˆæœ¬è¾ƒé«˜

## é¡¹ç›®ç»“æ„

```
clickzetta_aisql/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ai_functions_complete.py     # æ ¸å¿ƒå®ç°æ–‡ä»¶
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_complete_coverage.py    # å®Œæ•´æµ‹è¯•å¥—ä»¶
â”‚   â”œâ”€â”€ quick_validation.py          # å¿«é€ŸéªŒè¯è„šæœ¬
â”‚   â””â”€â”€ smart_analyzer.py            # æ™ºèƒ½åˆ†æå·¥å…·
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ package_with_deps.py         # æ‰“åŒ…è„šæœ¬
â”‚   â”œâ”€â”€ fix_*.py                     # ä¿®å¤è„šæœ¬
â”‚   â””â”€â”€ optimize_*.py                # ä¼˜åŒ–è„šæœ¬
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ test_config.json             # æµ‹è¯•é…ç½®
â”‚   â””â”€â”€ batch_test_data.json         # æ‰¹é‡æµ‹è¯•æ•°æ®
â””â”€â”€ user_docs/                       # ç”¨æˆ·æ–‡æ¡£
```

## å‡½æ•°å¼€å‘è§„èŒƒ

### 1. å‡½æ•°ç­¾åè§„èŒƒ

```python
from clickzetta.external_function.annotate import annotate

@annotate("ai_function_name", 
    [{"name": "param1", "type": "string"},
     {"name": "param2", "type": "string"}, 
     {"name": "api_key", "type": "string"},
     {"name": "optional_param", "type": "string", "optional": True}],
    {"type": "string"})
def ai_function_name_impl(rows):
    """å‡½æ•°è¯´æ˜æ–‡æ¡£"""
    results = []
    for row in rows:
        try:
            # å¤„ç†é€»è¾‘
            result = process_with_ai(row[0], row[1], row[2])
            results.append(json.dumps(result, ensure_ascii=False))
        except Exception as e:
            results.append(json.dumps({
                "error": f"å¤„ç†å¤±è´¥: {str(e)}"
            }, ensure_ascii=False))
    return results
```

### 2. å‚æ•°è®¾è®¡åŸåˆ™

1. **å¿…éœ€å‚æ•°åœ¨å‰**ï¼šè¾“å…¥æ•°æ® â†’ APIå¯†é’¥ â†’ å¯é€‰å‚æ•°
2. **åˆç†çš„é»˜è®¤å€¼**ï¼šæ¨¡å‹åç§°ã€æ¸©åº¦ç­‰å‚æ•°åº”æœ‰é»˜è®¤å€¼
3. **å‚æ•°éªŒè¯**ï¼šæ£€æŸ¥å¿…éœ€å‚æ•°æ˜¯å¦ä¸ºç©º
4. **ç±»å‹ä¸€è‡´**ï¼šæ‰€æœ‰å‚æ•°ç±»å‹ç»Ÿä¸€ä¸º "string"

### 3. è¿”å›å€¼è§„èŒƒ

```python
# æˆåŠŸè¿”å›
{
    "result": "å¤„ç†ç»“æœ",
    "metadata": {
        "model": "qwen-plus",
        "tokens": 150,
        "processing_time": 1.23
    }
}

# é”™è¯¯è¿”å›
{
    "error": "é”™è¯¯ä¿¡æ¯",
    "error_type": "InvalidInput",
    "suggestion": "è¯·æ£€æŸ¥è¾“å…¥å‚æ•°"
}
```

## æ·»åŠ æ–°å‡½æ•°æŒ‡å—

### æ­¥éª¤1ï¼šè®¾è®¡å‡½æ•°æ¥å£

```python
# 1. ç¡®å®šå‡½æ•°åç§°ï¼ˆéµå¾ª ai_category_action å‘½åè§„èŒƒï¼‰
function_name = "ai_text_classify"

# 2. å®šä¹‰å‚æ•°åˆ—è¡¨
params = [
    {"name": "text", "type": "string"},
    {"name": "categories", "type": "string"},  # JSONæ•°ç»„
    {"name": "api_key", "type": "string"},
    {"name": "model_name", "type": "string", "optional": True}
]

# 3. å®šä¹‰è¿”å›ç±»å‹
return_type = {"type": "string"}  # JSONæ ¼å¼
```

### æ­¥éª¤2ï¼šå®ç°å‡½æ•°é€»è¾‘

```python
@annotate("ai_text_classify", params, return_type)
def ai_text_classify_impl(rows):
    """æ–‡æœ¬åˆ†ç±»å‡½æ•°"""
    results = []
    
    for row in rows:
        try:
            text = row[0]
            categories = json.loads(row[1]) if row[1] else []
            api_key = row[2]
            model_name = row[3] if len(row) > 3 and row[3] else "qwen-plus"
            
            # å‚æ•°éªŒè¯
            if not text or not categories or not api_key:
                raise ValueError("ç¼ºå°‘å¿…éœ€å‚æ•°")
            
            # è°ƒç”¨AIæœåŠ¡
            result = call_dashscope_api(
                text=text,
                categories=categories,
                api_key=api_key,
                model=model_name
            )
            
            results.append(json.dumps(result, ensure_ascii=False))
            
        except Exception as e:
            results.append(json.dumps({
                "error": str(e),
                "error_type": type(e).__name__
            }, ensure_ascii=False))
    
    return results
```

### æ­¥éª¤3ï¼šæ·»åŠ æµ‹è¯•ç”¨ä¾‹

åœ¨ `test_complete_coverage.py` ä¸­æ·»åŠ ï¼š

```python
"ai_text_classify": {
    "params": {
        "text": "è¿™æ˜¯ä¸€æ¡æ­£é¢çš„äº§å“è¯„ä»·",
        "categories": '["æ­£é¢", "è´Ÿé¢", "ä¸­æ€§"]',
        "model_name": "qwen-plus"
    },
    "category": "æ–‡æœ¬å¤„ç†",
    "expected_fields": ["category", "confidence", "reasoning"]
}
```

### æ­¥éª¤4ï¼šæ–‡æ¡£åŒ–

åœ¨ `user_docs/07_FUNCTION_REFERENCE.md` ä¸­æ·»åŠ å‡½æ•°è¯´æ˜ã€‚

## è°ƒè¯•æŠ€å·§

### 1. æœ¬åœ°è°ƒè¯•

```python
# åˆ›å»ºè°ƒè¯•è„šæœ¬ debug_function.py
import sys
sys.path.insert(0, 'src')
from ai_functions_complete import ai_text_classify_impl

# æ¨¡æ‹ŸClickZettaè°ƒç”¨
test_rows = [
    ["æµ‹è¯•æ–‡æœ¬", '["åˆ†ç±»1", "åˆ†ç±»2"]', "sk-xxx", "qwen-plus"]
]

results = ai_text_classify_impl(test_rows)
print(results[0])
```

### 2. æ—¥å¿—è°ƒè¯•

```python
import logging

# åœ¨å‡½æ•°å¼€å§‹å¤„æ·»åŠ 
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# åœ¨å…³é”®ä½ç½®æ·»åŠ æ—¥å¿—
logger.debug(f"Input parameters: {row}")
logger.info(f"API response: {response}")
```

### 3. é”™è¯¯å¤„ç†å¢å¼º

```python
try:
    # ä¸»è¦é€»è¾‘
    pass
except dashscope.errors.AuthenticationError:
    error_msg = "APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®"
except dashscope.errors.RateLimitError:
    error_msg = "APIè°ƒç”¨é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åé‡è¯•"
except Exception as e:
    error_msg = f"æœªçŸ¥é”™è¯¯: {str(e)}"
    logger.exception("Unexpected error")
```

## æ€§èƒ½ä¼˜åŒ–

### 1. å“åº”å¤§å°ä¼˜åŒ–ï¼ˆJIRA-001 éœ€æ±‚ï¼‰

#### èƒŒæ™¯ï¼šä¼˜åŒ–å‰çš„é—®é¢˜
åœ¨é¡¹ç›®åˆæœŸï¼Œè®¸å¤šå‡½æ•°è¿”å›äº†å¤§é‡å†—ä½™å†…å®¹ï¼š
- é‡å¤çš„è§£é‡Šæ–‡æœ¬ï¼ˆå¦‚"æ ¹æ®æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘ä¸ºæ‚¨..."ï¼‰
- è¿‡åº¦è¯¦ç»†çš„æ­¥éª¤è¯´æ˜
- ä¸å¿…è¦çš„æ ¼å¼åŒ–å­—ç¬¦
- å¹³å‡å“åº”å¤§å°ï¼š15-20KB
- æŸäº›å‡½æ•°ç”šè‡³è¾¾åˆ° 50KB+

#### ğŸ¯ ä¼˜åŒ–ç›®æ ‡
- è¾¾åˆ° JIRA-001 è¦æ±‚ï¼š67% çš„å‹ç¼©ç‡
- ä¿æŒåŠŸèƒ½å®Œæ•´æ€§
- æå‡ç”¨æˆ·ä½“éªŒ

#### ä¼˜åŒ–ç­–ç•¥å’Œå®ç°

**ç­–ç•¥1ï¼šæ¶ˆé™¤å†—ä½™çš„ç¤¼è²Œç”¨è¯­**
```python
# âŒ ä¼˜åŒ–å‰
def process_response_old(text):
    return f"""
    æ‚¨å¥½ï¼æ„Ÿè°¢æ‚¨ä½¿ç”¨æˆ‘ä»¬çš„AIæœåŠ¡ã€‚
    æ ¹æ®æ‚¨æä¾›çš„æ–‡æœ¬å†…å®¹ï¼Œæˆ‘å·²ç»ä¸ºæ‚¨å®Œæˆäº†å¤„ç†ã€‚
    ä»¥ä¸‹æ˜¯è¯¦ç»†çš„å¤„ç†ç»“æœï¼š
    
    {actual_result}
    
    å¸Œæœ›è¿™ä¸ªç»“æœå¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ã€‚
    å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–éœ€æ±‚ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚
    """

# âœ… ä¼˜åŒ–å
def process_response_new(text):
    return actual_result  # ç›´æ¥è¿”å›æ ¸å¿ƒç»“æœ
```

**ç­–ç•¥2ï¼šç²¾ç®€è¿”å›ç»“æ„**
```python
# âŒ ä¼˜åŒ–å‰ - è¿‡åº¦åµŒå¥—çš„ç»“æ„
{
    "status": "success",
    "code": 200,
    "message": "å¤„ç†æˆåŠŸ",
    "data": {
        "result": {
            "content": "å®é™…å†…å®¹",
            "metadata": {
                "process_time": "2.3s",
                "model_used": "qwen-plus",
                "version": "1.0"
            }
        }
    },
    "timestamp": "2024-01-01T00:00:00Z"
}

# âœ… ä¼˜åŒ–å - æ‰å¹³åŒ–ç»“æ„
{
    "result": "å®é™…å†…å®¹",
    "model": "qwen-plus",
    "time": 2.3
}
```

**ç­–ç•¥3ï¼šåŠ¨æ€å­—æ®µè¿”å›**
```python
def optimize_sentiment_response(sentiment_result):
    """æ ¹æ®ç»“æœåŠ¨æ€å†³å®šè¿”å›å­—æ®µ"""
    # åŸºç¡€ç»“æœ
    response = {
        "sentiment": sentiment_result["label"],
        "score": sentiment_result["score"]
    }
    
    # åªåœ¨éœ€è¦æ—¶æ·»åŠ é¢å¤–ä¿¡æ¯
    if sentiment_result["score"] < 0.7:  # ç½®ä¿¡åº¦ä½æ—¶
        response["confidence"] = "low"
        response["suggestion"] = "ç»“æœä»…ä¾›å‚è€ƒ"
    
    # ç§»é™¤æ‰€æœ‰nullæˆ–ç©ºå­—æ®µ
    return {k: v for k, v in response.items() if v}
```

**ç­–ç•¥4ï¼šæ™ºèƒ½æˆªæ–­é•¿æ–‡æœ¬**
```python
def smart_truncate(text, max_length=1000):
    """æ™ºèƒ½æˆªæ–­ï¼Œä¿æŒè¯­ä¹‰å®Œæ•´"""
    if len(text) <= max_length:
        return text
    
    # åœ¨å¥å·ã€é—®å·ã€æ„Ÿå¹å·å¤„æˆªæ–­
    for sep in ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?']:
        pos = text.rfind(sep, 0, max_length)
        if pos > max_length * 0.8:  # è‡³å°‘ä¿ç•™80%
            return text[:pos + 1]
    
    # å¦‚æœæ²¡æ‰¾åˆ°åˆé€‚çš„æ–­ç‚¹ï¼Œåœ¨æœ€åä¸€ä¸ªé€—å·å¤„æˆªæ–­
    pos = text.rfind('ï¼Œ', 0, max_length)
    if pos > max_length * 0.8:
        return text[:pos] + "..."
    
    # æœ€åçš„é€‰æ‹©ï¼šç¡¬æˆªæ–­
    return text[:max_length] + "..."
```

**ç­–ç•¥5ï¼šç§»é™¤APIåŸå§‹å“åº”çš„å†—ä½™**
```python
def clean_api_response(api_response):
    """æ¸…ç†APIå“åº”ä¸­çš„å†—ä½™å†…å®¹"""
    # DashScope API ç»å¸¸è¿”å›è¿™æ ·çš„å†…å®¹
    redundant_prefixes = [
        "æ ¹æ®æ‚¨çš„è¦æ±‚ï¼Œ",
        "æˆ‘å·²ç»ä¸ºæ‚¨",
        "ä»¥ä¸‹æ˜¯",
        "åŸºäºæä¾›çš„å†…å®¹ï¼Œ",
        "ç»è¿‡åˆ†æï¼Œ"
    ]
    
    result = api_response
    for prefix in redundant_prefixes:
        if result.startswith(prefix):
            result = result[len(prefix):]
            break
    
    # ç§»é™¤ç»“å°¾çš„å†—ä½™
    redundant_suffixes = [
        "å¸Œæœ›å¯¹æ‚¨æœ‰å¸®åŠ©ã€‚",
        "å¦‚æœ‰å…¶ä»–é—®é¢˜è¯·å‘Šè¯‰æˆ‘ã€‚",
        "è¯·é—®è¿˜æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"
    ]
    
    for suffix in redundant_suffixes:
        if result.endswith(suffix):
            result = result[:-len(suffix)].rstrip()
            break
    
    return result.strip()
```

#### å®é™…ä¼˜åŒ–æ¡ˆä¾‹

**æ¡ˆä¾‹1ï¼šæ–‡æœ¬æ‘˜è¦ä¼˜åŒ–**
```python
# ä¼˜åŒ–å‰ï¼šå¹³å‡ 8KB
{
    "status": "success",
    "summary": {
        "content": "æ ¹æ®æ‚¨æä¾›çš„æ–‡ç« ï¼Œæˆ‘ä¸ºæ‚¨ç”Ÿæˆäº†ä»¥ä¸‹æ‘˜è¦ï¼šæœ¬æ–‡ä¸»è¦è®²è¿°äº†...",
        "key_points": [
            "è¦ç‚¹1ï¼šè¯¦ç»†è¯´æ˜...",
            "è¦ç‚¹2ï¼šè¯¦ç»†è¯´æ˜...",
            "è¦ç‚¹3ï¼šè¯¦ç»†è¯´æ˜..."
        ],
        "metadata": {
            "original_length": 5000,
            "summary_length": 500,
            "compression_ratio": 0.1,
            "processing_time": "2.3s"
        }
    }
}

# ä¼˜åŒ–åï¼šå¹³å‡ 2KB (75% å‹ç¼©)
{
    "summary": "æœ¬æ–‡ä¸»è¦è®²è¿°äº†...",
    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"],
    "length": 500
}
```

**æ¡ˆä¾‹2ï¼šæƒ…æ„Ÿåˆ†æä¼˜åŒ–**
```python
# ä¼˜åŒ–å‰ï¼š3KB
{
    "analysis_result": {
        "sentiment": {
            "label": "æ­£é¢",
            "score": 0.95,
            "confidence": "high",
            "details": {
                "positive_score": 0.95,
                "negative_score": 0.03,
                "neutral_score": 0.02
            }
        },
        "explanation": "è¿™æ®µæ–‡æœ¬è¡¨è¾¾äº†ç§¯ææ­£é¢çš„æƒ…æ„Ÿ..."
    }
}

# ä¼˜åŒ–åï¼š200B (93% å‹ç¼©)
{
    "sentiment": "æ­£é¢",
    "score": 0.95
}
```

#### ä¼˜åŒ–ç»“æœç»Ÿè®¡

| å‡½æ•°ç±»åˆ« | ä¼˜åŒ–å‰å¹³å‡å¤§å° | ä¼˜åŒ–åå¹³å‡å¤§å° | å‹ç¼©ç‡ |
|---------|--------------|--------------|--------|
| æ–‡æœ¬å¤„ç† | 8-15 KB | 2-3 KB | 75-80% |
| æƒ…æ„Ÿåˆ†æ | 3-5 KB | 200-500 B | 90-93% |
| å®ä½“æå– | 10-20 KB | 3-5 KB | 70-75% |
| ä¸šåŠ¡åœºæ™¯ | 15-30 KB | 5-8 KB | 67-73% |

#### ç‰¹æ®Šå¤„ç†ï¼šå‘é‡å‡½æ•°ä¿æŒä¸å˜
```python
# å‘é‡å‡½æ•°ä¸åº”è¯¥ä¼˜åŒ–ï¼Œå› ä¸ºæ•°æ®æœ¬èº«å°±æ˜¯å¿…éœ€çš„
def handle_vector_response(vector_data):
    """å‘é‡æ•°æ®ä¿æŒå®Œæ•´"""
    # 20-30KB çš„å‘é‡æ•°æ®æ˜¯æ­£å¸¸çš„
    return {
        "embedding": vector_data,  # 1536ç»´æˆ–1024ç»´æµ®ç‚¹æ•°
        "model": "text-embedding-v2",
        "dimensions": len(vector_data)
    }
```

#### ä¼˜åŒ–åçš„é€šç”¨å“åº”å¤„ç†å™¨
```python
def optimize_response(result, function_type="general", max_size=5000):
    """é€šç”¨å“åº”ä¼˜åŒ–å™¨"""
    # å‘é‡ç±»å‡½æ•°ä¸ä¼˜åŒ–
    if function_type in ["vector", "embedding"]:
        return json.dumps(result, ensure_ascii=False)
    
    # ç¬¬ä¸€æ­¥ï¼šæ¸…ç†å†—ä½™æ–‡æœ¬
    if isinstance(result, dict):
        for key in ["result", "content", "summary", "analysis"]:
            if key in result and isinstance(result[key], str):
                result[key] = clean_api_response(result[key])
    
    # ç¬¬äºŒæ­¥ï¼šç§»é™¤nullå’Œç©ºå€¼
    result = remove_empty_values(result)
    
    # ç¬¬ä¸‰æ­¥ï¼šæ™ºèƒ½æˆªæ–­
    result_str = json.dumps(result, ensure_ascii=False)
    if len(result_str) > max_size:
        # æ ¹æ®å‡½æ•°ç±»å‹é‡‡ç”¨ä¸åŒç­–ç•¥
        if function_type == "summary":
            result = truncate_summary(result, max_size)
        elif function_type == "analysis":
            result = simplify_analysis(result)
        else:
            result = generic_truncate(result, max_size)
    
    return json.dumps(result, ensure_ascii=False)

def remove_empty_values(obj):
    """é€’å½’ç§»é™¤ç©ºå€¼"""
    if isinstance(obj, dict):
        return {k: remove_empty_values(v) 
                for k, v in obj.items() 
                if v is not None and v != "" and v != []}
    elif isinstance(obj, list):
        return [remove_empty_values(item) 
                for item in obj 
                if item is not None and item != ""]
    return obj
```

#### ä¼˜åŒ–ç»éªŒæ€»ç»“

1. **è¯†åˆ«çœŸæ­£çš„ä»·å€¼**ï¼šç”¨æˆ·éœ€è¦çš„æ˜¯æ•°æ®ï¼Œä¸æ˜¯å®¢å¥—è¯
2. **åˆ†ç±»å¤„ç†**ï¼šä¸åŒç±»å‹çš„å‡½æ•°éœ€è¦ä¸åŒçš„ä¼˜åŒ–ç­–ç•¥
3. **ä¿æŠ¤æ ¸å¿ƒæ•°æ®**ï¼šå‘é‡ã€OCRç»“æœç­‰ä¸åº”è¿‡åº¦ä¼˜åŒ–
4. **æµ‹è¯•é©±åŠ¨**ï¼šæ¯æ¬¡ä¼˜åŒ–åéƒ½è¦éªŒè¯åŠŸèƒ½å®Œæ•´æ€§
5. **ç›‘æ§æ•ˆæœ**ï¼šæŒç»­è·Ÿè¸ªä¼˜åŒ–åçš„å®é™…æ•ˆæœ

### 2. æ‰¹å¤„ç†ä¼˜åŒ–

```python
# å¯¹äºæ”¯æŒæ‰¹å¤„ç†çš„APIï¼Œåˆå¹¶è¯·æ±‚
def process_batch(rows, batch_size=10):
    results = []
    for i in range(0, len(rows), batch_size):
        batch = rows[i:i+batch_size]
        batch_results = call_batch_api(batch)
        results.extend(batch_results)
    return results
```

### 3. ç¼“å­˜ç­–ç•¥

```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def cached_api_call(text_hash, model):
    """ç¼“å­˜ç›¸åŒè¾“å…¥çš„APIè°ƒç”¨ç»“æœ"""
    return call_api(text_hash, model)
```

## éƒ¨ç½²æ•…éšœæ’æŸ¥

### ğŸš¨ é‡è¦ï¼šå‡½æ•°è®¡ç®—æœåŠ¡å™¨æ‰¾ä¸åˆ°å‡½æ•°çš„é—®é¢˜

è¿™æ˜¯éƒ¨ç½²è¿‡ç¨‹ä¸­æœ€å¸¸è§ä¸”æœ€éš¾æ’æŸ¥çš„é—®é¢˜ã€‚ä»¥ä¸‹æ˜¯å®Œæ•´çš„æ’æŸ¥å’Œè§£å†³æ–¹æ¡ˆã€‚

#### é—®é¢˜ç°è±¡
- ClickZettaæŠ¥é”™ï¼š`å‡½æ•° 'ai_text_summarize' ä¸å­˜åœ¨`
- å‡½æ•°è®¡ç®—æœåŠ¡å™¨æ—¥å¿—æ˜¾ç¤ºï¼š`No function named 'ai_text_summarize' found`
- ZIPåŒ…å·²ä¸Šä¼ ï¼Œä½†å‡½æ•°æ— æ³•è°ƒç”¨

#### æ ¹æœ¬åŸå› 
1. **è£…é¥°å™¨é—®é¢˜**ï¼š`@annotate` è£…é¥°å™¨æœªæ­£ç¡®æ³¨å†Œå‡½æ•°
2. **å¯¼å…¥é—®é¢˜**ï¼šPythonæ¨¡å—æœªæ­£ç¡®åŠ è½½
3. **è·¯å¾„é—®é¢˜**ï¼šZIPåŒ…ç»“æ„ä¸æ­£ç¡®

#### è§£å†³æ–¹æ¡ˆæ£€æŸ¥æ¸…å•

##### 1. éªŒè¯å‡½æ•°å®šä¹‰æ ¼å¼
```python
# âœ… æ­£ç¡®æ ¼å¼
@annotate("ai_text_summarize", 
    [{"name": "text", "type": "string"},
     {"name": "api_key", "type": "string"},
     {"name": "model_name", "type": "string", "optional": True},
     {"name": "max_length", "type": "string", "optional": True}],
    {"type": "string"})
def ai_text_summarize_impl(rows):
    # å®ç°ä»£ç 
    pass

# âŒ é”™è¯¯æ ¼å¼
def ai_text_summarize(rows):  # ç¼ºå°‘è£…é¥°å™¨
    pass

@annotate("ai_text_summarize")  # ç¼ºå°‘å‚æ•°å®šä¹‰
def ai_text_summarize_impl(rows):
    pass
```

##### 2. éªŒè¯ZIPåŒ…ç»“æ„
```bash
# æ£€æŸ¥ZIPåŒ…å†…å®¹
unzip -l clickzetta_ai_functions_full.zip | head -20

# æ­£ç¡®çš„ç»“æ„åº”è¯¥æ˜¯ï¼š
# ai_functions_complete.py  ï¼ˆåœ¨æ ¹ç›®å½•ï¼‰
# dashscope/
# requests/
# ...å…¶ä»–ä¾èµ–
```

##### 3. éªŒè¯å‡½æ•°æ³¨å†Œ
```python
# åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ è°ƒè¯•ä»£ç ï¼ˆä»…ç”¨äºæœ¬åœ°æµ‹è¯•ï¼‰
if __name__ == "__main__":
    # åˆ—å‡ºæ‰€æœ‰æ³¨å†Œçš„å‡½æ•°
    import sys
    from clickzetta.external_function import registry
    
    print("Registered functions:")
    for func_name in registry.get_all_functions():
        print(f"  - {func_name}")
```

##### 4. éªŒè¯æ¨¡å—å¯¼å…¥
```python
# ç¡®ä¿æ‰€æœ‰å¿…è¦çš„å¯¼å…¥éƒ½åœ¨æ–‡ä»¶é¡¶éƒ¨
import json
import logging
from clickzetta.external_function.annotate import annotate
import dashscope
from dashscope import Generation
from http import HTTPStatus

# è®¾ç½®æ—¥å¿—ï¼ˆå¸®åŠ©è°ƒè¯•ï¼‰
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
```

##### 5. åˆ›å»ºæœ€å°æµ‹è¯•å‡½æ•°
```python
# ç”¨äºéªŒè¯éƒ¨ç½²ç¯å¢ƒçš„æœ€å°å‡½æ•°
@annotate("test_echo", 
    [{"name": "input", "type": "string"}],
    {"type": "string"})
def test_echo_impl(rows):
    """ç®€å•çš„å›æ˜¾å‡½æ•°ï¼Œç”¨äºæµ‹è¯•éƒ¨ç½²"""
    results = []
    for row in rows:
        results.append(f"Echo: {row[0]}")
    return results
```

#### éƒ¨ç½²éªŒè¯æ­¥éª¤

1. **æœ¬åœ°éªŒè¯**
```bash
# åˆ›å»ºæµ‹è¯•è„šæœ¬
cat > test_functions.py << 'EOF'
import sys
sys.path.insert(0, '.')
from ai_functions_complete import *

# æµ‹è¯•å‡½æ•°æ˜¯å¦å¯ä»¥å¯¼å…¥
print("Testing import...")
try:
    test_rows = [["test", "sk-xxx"]]
    result = ai_text_summarize_impl(test_rows)
    print("âœ… Import successful")
except Exception as e:
    print(f"âŒ Import failed: {e}")
EOF

python test_functions.py
```

2. **æ‰“åŒ…éªŒè¯**
```bash
# åˆ›å»ºå¹²å‡€çš„æ‰“åŒ…ç¯å¢ƒ
rm -rf temp_package
mkdir temp_package

# å¤åˆ¶ä¸»æ–‡ä»¶
cp src/ai_functions_complete.py temp_package/

# å®‰è£…ä¾èµ–
pip install dashscope --target temp_package/

# åˆ›å»ºZIPåŒ…
cd temp_package
zip -r ../test_package.zip .
cd ..

# éªŒè¯ZIPåŒ…
unzip -t test_package.zip
```

3. **éƒ¨ç½²åéªŒè¯**
```sql
-- åœ¨ClickZettaä¸­æµ‹è¯•æœ€ç®€å•çš„å‡½æ•°
SELECT test_echo('Hello World');

-- å¦‚æœtest_echoå·¥ä½œï¼Œå†æµ‹è¯•å…¶ä»–å‡½æ•°
SELECT ai_text_summarize('æµ‹è¯•æ–‡æœ¬', 'sk-xxx');
```

#### å†å²é—®é¢˜æ€»ç»“

åœ¨é¡¹ç›®åˆæœŸï¼Œæˆ‘ä»¬é‡åˆ°äº†ä»¥ä¸‹é—®é¢˜ï¼š

1. **é—®é¢˜1ï¼šå‡½æ•°åä¸åŒ¹é…**
   - ç—‡çŠ¶ï¼š`ai_text_summarize` vs `ai_text_summarize_impl`
   - è§£å†³ï¼šç¡®ä¿è£…é¥°å™¨ä¸­çš„åç§°ä¸SQLè°ƒç”¨ä¸€è‡´

2. **é—®é¢˜2ï¼šå‚æ•°æ•°é‡ä¸åŒ¹é…**
   - ç—‡çŠ¶ï¼šæœŸæœ›3ä¸ªå‚æ•°ï¼Œå®é™…ä¼ å…¥4ä¸ª
   - è§£å†³ï¼šæ‰€æœ‰å¯é€‰å‚æ•°å¿…é¡»æ ‡è®° `"optional": True`

3. **é—®é¢˜3ï¼šä¾èµ–åŒ…ç¼ºå¤±**
   - ç—‡çŠ¶ï¼š`ModuleNotFoundError: No module named 'dashscope'`
   - è§£å†³ï¼šç¡®ä¿æ‰€æœ‰ä¾èµ–éƒ½æ‰“åŒ…åˆ°ZIPä¸­

4. **é—®é¢˜4ï¼šPythonç‰ˆæœ¬ä¸å…¼å®¹**
   - ç—‡çŠ¶ï¼šè¯­æ³•é”™è¯¯æˆ–å¯¼å…¥é”™è¯¯
   - è§£å†³ï¼šä½¿ç”¨Python 3.8ï¼ˆClickZettaè¿è¡Œæ—¶ç‰ˆæœ¬ï¼‰

#### è°ƒè¯•å»ºè®®

1. **å¯ç”¨è¯¦ç»†æ—¥å¿—**
```python
# åœ¨å‡½æ•°å¼€å§‹å¤„æ·»åŠ 
logger.info(f"Function called with {len(rows)} rows")
logger.debug(f"First row: {rows[0] if rows else 'No rows'}")
```

2. **æ·»åŠ é”™è¯¯è¾¹ç•Œ**
```python
try:
    # ä¸»é€»è¾‘
    pass
except Exception as e:
    logger.exception("Unexpected error in function")
    return [json.dumps({"error": str(e), "type": type(e).__name__})]
```

3. **åˆ†é˜¶æ®µæµ‹è¯•ï¼ˆæ¨èæ–¹æ³•ï¼‰**

è¿™æ˜¯æˆ‘ä»¬åœ¨å®é™…é¡¹ç›®ä¸­éªŒè¯æœ€æœ‰æ•ˆçš„è°ƒè¯•æ–¹æ¡ˆï¼Œé€šè¿‡é€æ­¥å¢åŠ å¤æ‚åº¦æ¥å®šä½é—®é¢˜ã€‚

**é˜¶æ®µ1ï¼šéªŒè¯åŸºç¡€ç¯å¢ƒ**
```python
# step1_basic.py - æœ€ç®€å•çš„å‡½æ•°ï¼Œä¸ä¾èµ–ä»»ä½•å¤–éƒ¨åº“
@annotate("test_basic", 
    [{"name": "input", "type": "string"}],
    {"type": "string"})
def test_basic_impl(rows):
    """éªŒè¯ClickZettaèƒ½æ‰¾åˆ°å¹¶æ‰§è¡Œå‡½æ•°"""
    return [f"Basic test: {row[0]}" for row in rows]
```

**é˜¶æ®µ2ï¼šéªŒè¯JSONå¤„ç†**
```python
# step2_json.py - æµ‹è¯•JSONåºåˆ—åŒ–
import json

@annotate("test_json", 
    [{"name": "input", "type": "string"}],
    {"type": "string"})
def test_json_impl(rows):
    """éªŒè¯JSONå¤„ç†èƒ½åŠ›"""
    results = []
    for row in rows:
        result = {"input": row[0], "processed": True}
        results.append(json.dumps(result, ensure_ascii=False))
    return results
```

**é˜¶æ®µ3ï¼šéªŒè¯å¤–éƒ¨ä¾èµ–**
```python
# step3_dependencies.py - æµ‹è¯•dashscopeå¯¼å…¥
import json
import dashscope  # æµ‹è¯•å¤–éƒ¨ä¾èµ–

@annotate("test_dependencies", 
    [{"name": "input", "type": "string"}],
    {"type": "string"})
def test_dependencies_impl(rows):
    """éªŒè¯å¤–éƒ¨ä¾èµ–åŒ…èƒ½æ­£å¸¸å¯¼å…¥"""
    results = []
    for row in rows:
        result = {
            "input": row[0],
            "dashscope_version": dashscope.__version__,
            "status": "dependencies loaded"
        }
        results.append(json.dumps(result, ensure_ascii=False))
    return results
```

**é˜¶æ®µ4ï¼šéªŒè¯APIè°ƒç”¨ï¼ˆä½¿ç”¨çœŸå®APIå¯†é’¥ï¼‰**
```python
# step4_api_call.py - æµ‹è¯•çœŸå®APIè°ƒç”¨
import json
import dashscope
from dashscope import Generation

@annotate("test_api_call", 
    [{"name": "text", "type": "string"},
     {"name": "api_key", "type": "string"}],
    {"type": "string"})
def test_api_call_impl(rows):
    """éªŒè¯èƒ½å¦è°ƒç”¨DashScope API"""
    results = []
    for row in rows:
        try:
            dashscope.api_key = row[1]
            # æœ€ç®€å•çš„APIè°ƒç”¨
            response = Generation.call(
                model='qwen-turbo',
                prompt=row[0],
                max_tokens=10  # é™åˆ¶tokenèŠ‚çœæˆæœ¬
            )
            result = {
                "status": "success",
                "response": response.output.text[:50]
            }
        except Exception as e:
            result = {
                "status": "error",
                "error": str(e),
                "error_type": type(e).__name__
            }
        results.append(json.dumps(result, ensure_ascii=False))
    return results
```

**é˜¶æ®µ5ï¼šéƒ¨ç½²å®Œæ•´å‡½æ•°**
```python
# åªæœ‰å‰4ä¸ªé˜¶æ®µéƒ½æˆåŠŸåï¼Œæ‰éƒ¨ç½²å®Œæ•´çš„30ä¸ªå‡½æ•°
```

**è°ƒè¯•æµç¨‹**ï¼š
1. éƒ¨ç½²step1_basic.pyï¼Œæµ‹è¯•`SELECT test_basic('hello')`
   - å¦‚æœå¤±è´¥ï¼šæ£€æŸ¥handlerè·¯å¾„ã€å‡½æ•°æ³¨å†Œ
   - å¦‚æœæˆåŠŸï¼šç»§ç»­ä¸‹ä¸€æ­¥

2. éƒ¨ç½²step2_json.pyï¼Œæµ‹è¯•JSONè¿”å›
   - å¦‚æœå¤±è´¥ï¼šæ£€æŸ¥JSONåºåˆ—åŒ–é—®é¢˜
   - å¦‚æœæˆåŠŸï¼šåŸºç¡€ç¯å¢ƒæ­£å¸¸

3. éƒ¨ç½²step3_dependencies.pyï¼Œæµ‹è¯•ä¾èµ–åŒ…
   - å¦‚æœå¤±è´¥ï¼šæ£€æŸ¥ZIPåŒ…æ˜¯å¦åŒ…å«æ‰€æœ‰ä¾èµ–
   - å¦‚æœæˆåŠŸï¼šä¾èµ–åŠ è½½æ­£å¸¸

4. éƒ¨ç½²step4_api_call.pyï¼Œæµ‹è¯•APIè¿æ¥
   - å¦‚æœå¤±è´¥ï¼šæ£€æŸ¥ç½‘ç»œã€APIå¯†é’¥ã€æƒé™
   - å¦‚æœæˆåŠŸï¼šå¯ä»¥éƒ¨ç½²å®Œæ•´ç‰ˆæœ¬

**å®é™…æ¡ˆä¾‹**ï¼š
åœ¨æˆ‘ä»¬çš„é¡¹ç›®ä¸­ï¼Œé—®é¢˜åœ¨ç¬¬3é˜¶æ®µè¢«å‘ç° - dashscopeåŒ…æ²¡æœ‰æ­£ç¡®æ‰“åŒ…ã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬é¿å…äº†åœ¨30ä¸ªå‡½æ•°ä¸­é€ä¸€æ’æŸ¥ï¼Œå¤§å¤§æé«˜äº†è°ƒè¯•æ•ˆç‡ã€‚

## å¸¸è§é—®é¢˜

### Q1: å‡½æ•°è¶…æ—¶æ€ä¹ˆåŠï¼Ÿ

è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´ï¼š
```python
response = dashscope.Generation.call(
    model=model_name,
    messages=messages,
    timeout=30  # 30ç§’è¶…æ—¶
)
```

### Q2: å¦‚ä½•å¤„ç†å¤§æ–‡æœ¬è¾“å…¥ï¼Ÿ

```python
def process_large_text(text, max_length=6000):
    if len(text) > max_length:
        # åˆ†æ®µå¤„ç†
        chunks = [text[i:i+max_length] for i in range(0, len(text), max_length)]
        results = []
        for chunk in chunks:
            result = process_chunk(chunk)
            results.append(result)
        return merge_results(results)
    return process_text(text)
```

### Q3: å¦‚ä½•æ·»åŠ æ–°çš„AIèƒ½åŠ›ï¼Ÿ

1. ç¡®è®¤DashScope APIæ”¯æŒ
2. éµå¾ªç°æœ‰å‡½æ•°æ¨¡å¼
3. æ·»åŠ å®Œæ•´çš„é”™è¯¯å¤„ç†
4. ç¼–å†™æµ‹è¯•ç”¨ä¾‹
5. æ›´æ–°æ–‡æ¡£

### Q4: éƒ¨ç½²å‰æ£€æŸ¥æ¸…å•

- [ ] æ‰€æœ‰å‡½æ•°éƒ½æœ‰é”™è¯¯å¤„ç†
- [ ] è¿”å›å€¼æ ¼å¼ç»Ÿä¸€ä¸ºJSON
- [ ] å‚æ•°éªŒè¯å®Œæ•´
- [ ] æµ‹è¯•è¦†ç›–ç‡è¾¾æ ‡
- [ ] æ–‡æ¡£æ›´æ–°å®Œæˆ
- [ ] æ€§èƒ½æµ‹è¯•é€šè¿‡

## CREATE EXTERNAL FUNCTION å…³é”®æ³¨æ„äº‹é¡¹

### ğŸ¯ é‡è¦ï¼šåˆ›å»ºå‡½æ•°çš„å®Œæ•´æµç¨‹

#### 1. å‡†å¤‡API CONNECTIONï¼ˆå¿…é¡»å…ˆåˆ›å»ºï¼‰
```sql
-- åˆ›å»ºAPIè¿æ¥ï¼ˆé˜¿é‡Œäº‘ç¤ºä¾‹ï¼‰
CREATE API CONNECTION IF NOT EXISTS dashscope_api_conn
AS 'http://sls-vpc.aliyun.com/v1'
WITH
    ROLE_ARN = 'acs:ram::xxx:role/AliyunServiceRoleForSLS',
    CODE_BUCKET = 'your-oss-bucket-name';
```

#### 2. ä¸Šä¼ ZIPåŒ…åˆ°Volume
```sql
-- ä¸Šä¼ æ–‡ä»¶åˆ°Volumeï¼ˆç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼‰
PUT 'file:///Users/liangmo/Downloads/clickzetta_ai_functions_full.zip' 
TO 'volume://code_bucket/ai_functions/clickzetta_ai_functions_full.zip';
```

#### 3. åˆ›å»ºå¤–éƒ¨å‡½æ•°ï¼ˆæ­£ç¡®çš„è¯­æ³•ï¼‰
```sql
-- âœ… æ­£ç¡®çš„åˆ›å»ºè¯­å¥
CREATE OR REPLACE EXTERNAL FUNCTION ai_text_summarize(
    text STRING,
    api_key STRING,
    model_name STRING,
    max_length STRING
)
RETURNS STRING
AS 'volume://code_bucket/ai_functions/clickzetta_ai_functions_full.zip'
CONNECTION = dashscope_api_conn
RUNTIME = 'python3.8'
HANDLER = 'ai_functions_complete.ai_text_summarize_impl';

-- âŒ å¸¸è§é”™è¯¯
CREATE EXTERNAL FUNCTION ai_text_summarize  -- ç¼ºå°‘å‚æ•°å®šä¹‰
AS 'oss://bucket/file.zip'  -- åº”è¯¥ä½¿ç”¨volume://
HANDLER = 'ai_text_summarize';  -- åº”è¯¥æ˜¯æ¨¡å—å.å‡½æ•°å
```

#### 4. æ‰¹é‡åˆ›å»ºå‡½æ•°çš„æŠ€å·§
```sql
-- ä½¿ç”¨äº‹åŠ¡æ‰¹é‡åˆ›å»º
BEGIN;

-- æ–‡æœ¬å¤„ç†å‡½æ•°
CREATE OR REPLACE EXTERNAL FUNCTION ai_text_summarize...
CREATE OR REPLACE EXTERNAL FUNCTION ai_text_translate...
CREATE OR REPLACE EXTERNAL FUNCTION ai_text_sentiment_analyze...

-- å‘é‡å¤„ç†å‡½æ•°
CREATE OR REPLACE EXTERNAL FUNCTION ai_text_to_embedding...
CREATE OR REPLACE EXTERNAL FUNCTION ai_text_similarity...

COMMIT;
```

#### 5. éªŒè¯å‡½æ•°åˆ›å»ºæˆåŠŸ
```sql
-- æŸ¥çœ‹æ‰€æœ‰å¤–éƒ¨å‡½æ•°
SHOW FUNCTIONS LIKE 'ai_%';

-- æµ‹è¯•å‡½æ•°
SELECT ai_text_summarize(
    'è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬',
    'sk-your-api-key',
    'qwen-plus',
    '100'
);
```

### å¸¸è§CREATE FUNCTIONé”™è¯¯

1. **Handlerè·¯å¾„é”™è¯¯**
   ```sql
   -- âŒ é”™è¯¯
   HANDLER = 'ai_text_summarize_impl'  -- ç¼ºå°‘æ¨¡å—å
   
   -- âœ… æ­£ç¡®
   HANDLER = 'ai_functions_complete.ai_text_summarize_impl'
   ```

2. **å‚æ•°ä¸åŒ¹é…**
   ```sql
   -- âŒ é”™è¯¯ï¼šå‚æ•°æ•°é‡ä¸Pythonå‡½æ•°ä¸åŒ¹é…
   CREATE FUNCTION ai_text_summarize(text STRING, api_key STRING)
   -- ä½†Pythonå‡½æ•°æœŸæœ›4ä¸ªå‚æ•°
   
   -- âœ… æ­£ç¡®ï¼šåŒ…å«æ‰€æœ‰å‚æ•°
   CREATE FUNCTION ai_text_summarize(
       text STRING, 
       api_key STRING,
       model_name STRING,  -- å³ä½¿æ˜¯å¯é€‰å‚æ•°ä¹Ÿè¦å£°æ˜
       max_length STRING
   )
   ```

3. **Volumeè·¯å¾„é”™è¯¯**
   ```sql
   -- âŒ é”™è¯¯
   AS 's3://bucket/file.zip'
   AS 'oss://bucket/file.zip'
   AS '/path/to/file.zip'
   
   -- âœ… æ­£ç¡®
   AS 'volume://code_bucket/path/to/file.zip'
   ```

### éƒ¨ç½²æ£€æŸ¥æ¸…å•

- [ ] API CONNECTION å·²åˆ›å»º
- [ ] ZIPåŒ…å·²ä¸Šä¼ åˆ°Volume
- [ ] CREATE FUNCTIONè¯­å¥å‚æ•°ä¸Pythonå‡½æ•°åŒ¹é…
- [ ] Handleræ ¼å¼ä¸º `æ¨¡å—å.å‡½æ•°å`
- [ ] ä½¿ç”¨æ­£ç¡®çš„Volumeè·¯å¾„
- [ ] æŒ‡å®šæ­£ç¡®çš„RUNTIMEç‰ˆæœ¬
- [ ] æµ‹è¯•æ¯ä¸ªå‡½æ•°ç¡®ä¿å¯ç”¨

## æœ€ä½³å®è·µæ€»ç»“

1. **ä¿æŒä¸€è‡´æ€§**ï¼šå‡½æ•°å‘½åã€å‚æ•°é¡ºåºã€è¿”å›æ ¼å¼ä¿æŒä¸€è‡´
2. **ä¼˜é›…é™çº§**ï¼šAPIå¤±è´¥æ—¶è¿”å›æœ‰æ„ä¹‰çš„é”™è¯¯ä¿¡æ¯
3. **æ€§èƒ½æ„è¯†**ï¼šæ³¨æ„å“åº”å¤§å°å’Œå¤„ç†æ—¶é—´
4. **å®‰å…¨ç¬¬ä¸€**ï¼šä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç APIå¯†é’¥
5. **å……åˆ†æµ‹è¯•**ï¼šæ¯ä¸ªå‡½æ•°è‡³å°‘3ä¸ªæµ‹è¯•ç”¨ä¾‹
6. **æ–‡æ¡£å®Œæ•´**ï¼šä»£ç å³æ–‡æ¡£ï¼Œæ³¨é‡Šè¦æ¸…æ™°
7. **éƒ¨ç½²éªŒè¯**ï¼šæ¯æ¬¡éƒ¨ç½²åç«‹å³éªŒè¯å‡½æ•°å¯ç”¨æ€§

---

*æœ€åæ›´æ–°ï¼š2025-06-14*