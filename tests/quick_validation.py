#!/usr/bin/env python3
"""
å¿«é€ŸéªŒè¯è„šæœ¬
ç”¨äºŽå¿«é€ŸéªŒè¯å…³é”®å‡½æ•°çš„ä¼˜åŒ–æ•ˆæžœ
"""

import json
import sys
import time
from datetime import datetime

sys.path.insert(0, '/Users/liangmo/Documents/GitHub/clickzetta_aisql')

# å…³é”®å‡½æ•°åˆ—è¡¨ï¼ˆJIRA-001é‡ç‚¹ä¼˜åŒ–ç›®æ ‡ï¼‰
KEY_FUNCTIONS = [
    # å·²ä¼˜åŒ–çš„å‡½æ•°
    "ai_customer_segment",
    "ai_text_sentiment_analyze", 
    "ai_text_extract_keywords",
    "ai_customer_intent_analyze",
    "ai_sales_lead_score",
    
    # éœ€è¦éªŒè¯çš„å…¶ä»–å‡½æ•°
    "ai_text_summarize",
    "ai_text_translate",
    "ai_review_analyze",
    "ai_product_description_generate"
]


def validate_function(func_name: str, test_params: dict, api_key: str) -> dict:
    """éªŒè¯å•ä¸ªå‡½æ•°"""
    try:
        # åŠ¨æ€å¯¼å…¥
        module = __import__('ai_functions_complete')
        func_class = getattr(module, func_name, None)
        
        if not func_class:
            return {"status": "NOT_FOUND", "error": f"å‡½æ•°{func_name}æœªæ‰¾åˆ°"}
        
        # åˆ›å»ºå®žä¾‹å¹¶è°ƒç”¨
        func = func_class()
        params = test_params.copy()
        params["api_key"] = api_key
        
        start_time = time.time()
        result = func.evaluate(**params)
        execution_time = time.time() - start_time
        
        # åˆ†æžç»“æžœ
        result_size = len(result.encode('utf-8'))
        compression_rate = (1200 - result_size) / 1200 * 100
        
        # å°è¯•è§£æžJSON
        try:
            result_data = json.loads(result)
            json_valid = True
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å†—ä½™å†…å®¹
            has_redundancy = False
            if isinstance(result_data, dict):
                # æ£€æŸ¥å¸¸è§çš„å†—ä½™å­—æ®µ
                redundant_fields = ['model', 'timestamp', 'api_key', 'model_name']
                for field in redundant_fields:
                    if field in result_data:
                        has_redundancy = True
                        break
                
                # æ£€æŸ¥æ˜¯å¦æœ‰é•¿è§£é‡Šæ–‡æœ¬
                for key, value in result_data.items():
                    if isinstance(value, str) and len(value) > 500:
                        has_redundancy = True
                        break
        except:
            json_valid = False
            has_redundancy = True
            result_data = None
        
        return {
            "status": "SUCCESS",
            "execution_time": execution_time,
            "result_size": result_size,
            "compression_rate": compression_rate,
            "json_valid": json_valid,
            "has_redundancy": has_redundancy,
            "meets_jira_001": compression_rate >= 67 and result_size <= 400,
            "sample": result[:200] + "..." if len(result) > 200 else result
        }
        
    except Exception as e:
        return {"status": "ERROR", "error": str(e)}


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python quick_validation.py YOUR_API_KEY")
        return
    
    api_key = sys.argv[1]
    
    print("ðŸš€ JIRA-001 å¿«é€ŸéªŒè¯")
    print("=" * 60)
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ç›®æ ‡: åŽ‹ç¼©çŽ‡â‰¥67%, è¿”å›žå¤§å°â‰¤400å­—èŠ‚")
    print("=" * 60)
    
    # å®šä¹‰æµ‹è¯•å‚æ•°
    test_configs = {
        "ai_customer_segment": {
            "customer_data": '{"recency": 30, "frequency": 5, "monetary": 1500}',
            "segmentation_model": "RFM"
        },
        "ai_text_sentiment_analyze": {
            "text": "äº§å“è´¨é‡å¾ˆå¥½ï¼Œéžå¸¸æ»¡æ„ï¼"
        },
        "ai_text_extract_keywords": {
            "text": "äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ æ˜¯æœªæ¥æŠ€æœ¯å‘å±•çš„é‡è¦æ–¹å‘",
            "max_keywords": 3
        },
        "ai_customer_intent_analyze": {
            "customer_text": "æˆ‘æƒ³äº†è§£ä½ ä»¬çš„äº§å“ä»·æ ¼",
            "business_context": "general"
        },
        "ai_sales_lead_score": {
            "lead_info": '{"budget": 50000, "timeline": "1 month", "authority": "decision maker"}',
            "scoring_criteria": "BANT"
        },
        "ai_text_summarize": {
            "text": "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œæ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—é‡å¤§çªç ´ã€‚",
            "max_length": 50
        },
        "ai_text_translate": {
            "text": "Hello world",
            "target_language": "ä¸­æ–‡"
        },
        "ai_review_analyze": {
            "review_text": "äº§å“ä¸é”™ï¼Œä½†ä»·æ ¼åé«˜",
            "product_type": "general"
        },
        "ai_product_description_generate": {
            "product_info": '{"name": "æ™ºèƒ½æ‰‹è¡¨", "features": ["å¿ƒçŽ‡ç›‘æµ‹", "GPS"]}',
            "style": "professional"
        }
    }
    
    # æ‰§è¡ŒéªŒè¯
    results = []
    passed_count = 0
    
    for func_name in KEY_FUNCTIONS:
        if func_name not in test_configs:
            print(f"\nâš ï¸  {func_name}: ç¼ºå°‘æµ‹è¯•é…ç½®")
            continue
        
        print(f"\nðŸ” éªŒè¯: {func_name}")
        result = validate_function(func_name, test_configs[func_name], api_key)
        results.append({"function": func_name, **result})
        
        if result["status"] == "SUCCESS":
            status_icon = "âœ…" if result["meets_jira_001"] else "âŒ"
            print(f"  {status_icon} çŠ¶æ€: æˆåŠŸ")
            print(f"  â€¢ æ‰§è¡Œæ—¶é—´: {result['execution_time']:.2f}ç§’")
            print(f"  â€¢ è¿”å›žå¤§å°: {result['result_size']}å­—èŠ‚")
            print(f"  â€¢ åŽ‹ç¼©çŽ‡: {result['compression_rate']:.1f}%")
            print(f"  â€¢ JSONæœ‰æ•ˆ: {'æ˜¯' if result['json_valid'] else 'å¦'}")
            print(f"  â€¢ æœ‰å†—ä½™: {'æ˜¯' if result['has_redundancy'] else 'å¦'}")
            
            if result["meets_jira_001"]:
                passed_count += 1
        else:
            print(f"  âŒ çŠ¶æ€: å¤±è´¥ - {result.get('error', 'Unknown')}")
    
    # ç”Ÿæˆæ€»ç»“
    print("\n" + "=" * 60)
    print("ðŸ“Š éªŒè¯æ€»ç»“")
    print("=" * 60)
    
    success_results = [r for r in results if r["status"] == "SUCCESS"]
    if success_results:
        avg_compression = sum(r["compression_rate"] for r in success_results) / len(success_results)
        avg_size = sum(r["result_size"] for r in success_results) / len(success_results)
        
        print(f"âœ… æˆåŠŸéªŒè¯: {len(success_results)}/{len(KEY_FUNCTIONS)}")
        print(f"ðŸŽ¯ JIRA-001è¾¾æ ‡: {passed_count}/{len(success_results)} ({passed_count/len(success_results)*100:.1f}%)")
        print(f"ðŸ“Š å¹³å‡åŽ‹ç¼©çŽ‡: {avg_compression:.1f}%")
        print(f"ðŸ“ å¹³å‡è¿”å›žå¤§å°: {avg_size:.0f}å­—èŠ‚")
    
    # éœ€è¦ä¼˜åŒ–çš„å‡½æ•°
    need_optimization = [r for r in results if r["status"] == "SUCCESS" and not r["meets_jira_001"]]
    if need_optimization:
        print(f"\nâš ï¸  éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–çš„å‡½æ•°:")
        for r in need_optimization:
            print(f"  â€¢ {r['function']}: åŽ‹ç¼©çŽ‡{r['compression_rate']:.1f}%, å¤§å°{r['result_size']}å­—èŠ‚")
    
    # ä¿å­˜éªŒè¯ç»“æžœ
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    result_file = f"data/validation_result_{timestamp}.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump({
            "validation_time": datetime.now().isoformat(),
            "key_functions": KEY_FUNCTIONS,
            "results": results,
            "summary": {
                "total": len(KEY_FUNCTIONS),
                "success": len(success_results),
                "jira_001_passed": passed_count,
                "avg_compression": avg_compression if success_results else 0,
                "avg_size": avg_size if success_results else 0
            }
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nðŸ’¾ ç»“æžœå·²ä¿å­˜: {result_file}")


if __name__ == '__main__':
    main()